% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/wlr.power.maxcombo.R
\name{wlr.power.maxcombo}
\alias{wlr.power.maxcombo}
\title{Power Calculation for Group Sequential Design Using A Max-combo Test}
\usage{
wlr.power.maxcombo(
  T = c(24, 36, 48),
  events = NULL,
  alpha = c(0.01, 0.02, 0.02)/2,
  power = 0.9,
  side = 1,
  r = 1,
  n = NULL,
  h0 = function(t) {     log(2)/12 },
  S0 = function(t) {     exp(-log(2)/12 * t) },
  h1 = function(t) {     log(2)/12 * 0.7 },
  S1 = function(t) {     exp(-log(2)/12 * 0.7 * t) },
  f.logHR = function(t) {     log(as.numeric(t < 6) + as.numeric(t >= 6) * 0.65) },
  f.ws = list(IA1 = list(lr), IA2 = list(lr, fh01), FA = list(lr, fh01, fh11)),
  F.entry = function(t) {     (t/18) * as.numeric(t <= 18) + as.numeric(t > 18) },
  G.ltfu = function(t) {     0 },
  non.centrality = "Heetal2021",
  show.setting = "N"
)
}
\arguments{
\item{T}{Calendar time for analysis}

\item{events}{Target number of events}

\item{alpha}{Allocated alpha level. Default 0.025 (1-sided).}

\item{power}{Power, default 0.9}

\item{side}{Side of test 1 or 2. Default side = 1.}

\item{r}{Randomization ratio of experimental arm : control arm as r:1. When r = 1, it is equal allocation. Default r = 1.}

\item{n}{Total sample size for two arms. Default n = NULL. If n is not provided,
n will be calculated based on single-time point analysis using
the first weighted log-rank test as a starting point with alpha level.}

\item{h0}{Hazard function of control arm. h0(t) = log(2)/m0 means T~exponential distribution with median m0.}

\item{S0}{Survival function of control arm. In general, S0(t) = exp(- integral of h0(u) for u from 0 to t).
but providing S0(t) can improves computational efficiency and
usually the survival function is known in study design. The density function f0(t) = h0(t) * S0(t).}

\item{h1}{Hazard function of experimental arm. h1(t) = log(2)/m1 means T~exponential distribution with median m0.}

\item{S1}{Survival function of experimental arm. In general, S1(t) = exp(- integral of h1(u) for u from 0 to t).
but providing S1(t) can improves computational efficiency and
usually the survival function is known in study design. The density function f1(t) = h1(t) * S1(t).}

\item{f.logHR}{Log(hazard ratio) function, = log(h1(t) / h0(t)).}

\item{f.ws}{Weight functions of survival rate used for maxcombo test at each analysis.
For example (1), if there are 3 analyses planned including IA1, IA2, and FA.
IA1 uses log-rank test, IA2 uses a maxcombo test of (logrank, FH01),
and FA uses a maxcombo test of (logrank, FH01, FH11). Then specify as
f.ws = list(IA1=list(lr), IA2=list(lr, fh01), FA=list(lr, fh01, fh11)),
where define lr = function(s){1}; fh01=function(s){1-s}; fh11 = function(s){s*(1-s)};
For example (2), if only fh01 is used for all three analyses IA1, IA2 and FA.
f.ws = list(IA1=list(fh01), IA2=list(fh01), FA1=list(fh01)).
For example (3), if only logrank is used for a single time analysis, then
f.ws = list(IA1=list(lr)).}

\item{F.entry}{Distribution function of enrollment. For example,
F.entry(t) = (t/A)^psi*I(0<=t<=A) + I(t>A).
Default F.entry is uniform distribution function.}

\item{G.ltfu}{Distribution function of lost-to-follow-up censoring process. The observed
survival time is min(survival time, lost-to-follow-up time).
Default G.ltfu = 0 (no lost-to-followup)}

\item{non.centrality}{Option of non-centrality parameter either "Heetal2021"
or "Schoenfeld". Default "Heetal2021". The default method is more efficient
for HR < 0.65 in non-proportional hazards scenarios. No difference when HR > 0.65.}

\item{show.setting}{Option whether to show the recommended study design settings}
}
\value{
An object with dataframes below.
\itemize{
\item  mu:     Non-centrality parameter for each weighted log-rank test
included in the max-combo.
\item  events: Expected number of events at the calendar time T
\item  maturity: Maturity of each arm for each analysis
\item  T:      Expected calendar time for analysis (Data Cutoff Date)
\item  power:  Power of the max-combo test
\item  power.piece Power of each weighted log-rank test included in the max-combo test.
\item  overall.power Overall power of the study
\item  incremental.power Incremental power for each analysis.
The sum of all incremental powers is the overall power.
\item  n:       Total number of subjects for two arms
\item  medians: Median of each treatment group
\item  corr.Hp: Correlation matrix of the weighted log-rank tests included
in the max-combo test for the pooled distribution (H0).
\item  corr.strict.H0 Correlation matrix of the weighted log-rank tests included
in the max-combo test assuming the data strictly follow
the control arm distribution (Strict H0).
\item  wt: Weight functions used for each analysis
\item  bounds: Rejection boundary for the max-combo test after multiplicity
adjustment based on asymptotic multivariate normal distribution.
b.Hp: bound based on pooled distribution (preferred);
b.H0: bound based on strict H0
\item  setting Setting of the distribution for each arm (hazard function,
survival function, and log(HR) function), enrollment distribution
function, and lost-to-followup distribution.
}
}
\description{
This function calculates the power for group sequential design
based on the asymptotic
distribution of the weighted log-rank test statistic under H1, with provided
rejection boundaries.
For group sequential design, the power will be calculated for each analysis
and overall study. This function allows different max-combo tests for
for different analyses.

The non-centrality parameter can be chosen from Schoenfeld (1981) method,
or (He et al 2021) method (default).
The difference is usually negligible under most common situations with HR large.
However, when the assumed HR under H1 is small for weighted log-rank test, there is
notable small difference, in which scenario (He et al 2021) method can potentially
reduce sample size. Regarding the timing of analyses, either the calendar time
or required number of total events can be specified. By default, the required
number of total events will be used as determination of analysis cut off.
This function allows flexible alternative hypothesis in terms of HR(t), the
hazard ratio function over time. For delayed effect scenario under H1,
one can define HR(t) as a piecewise constant function of survival time t.
In addition, the function can handle user-defined flexible non-uniform enrollment
distribution function and independent time to lost-to-followup process which
is user-defined function of any lost-to-followup pattern such as constant
lost-to-followup rate or Weibull distribution. For most common setting
in practice, assuming the same lost-to-followup pattern in both arms.
}
\examples{
#Distributions for both arms
m0 = 12; #median RFS for control arm
lambda0 = log(2) / m0
h0 = function(t){lambda0}; 
S0 = function(t){exp(-lambda0 * t)}
HRd = 0.60 #hazard ratio after delay

h.D3=function(t){lambda0*as.numeric(t<3)+HRd*lambda0*as.numeric(t>=3)}
c3 = exp(-3*lambda0*(1-HRd)); 
S.D3 = function(t){S0(t)*as.numeric(t<3)+c3*exp(-HRd*lambda0*t)*as.numeric(t>=3)}
f.logHR.D3 = function(t){log(as.numeric(t<3) + as.numeric(t>= 3)*HRd)}

h.D6=function(t){lambda0*as.numeric(t<6)+HRd*lambda0*as.numeric(t>=6)}
c6 = exp(-6*lambda0*(1-HRd)); 
S.D6 = function(t){exp(-lambda0*t)*as.numeric(t<6)+c6*exp(-HRd*lambda0*t)*as.numeric(t>=6)}
f.logHR.D6 = function(t){log(as.numeric(t<6) + as.numeric(t>= 6)*HRd)}

#Define weight functions for weighted log-rank tests
lr = function(s){1}
fh01 = function(s){(1-s)}
fh11 = function(s){s*(1-s)}
#stabilized FH(0, 1; 0.5)
sfh01 = function(s){s1 = apply(cbind(s, 0.5), MARGIN=1,FUN=max); return(1-s1)} 
#modestly log-rank
mfh01 = function(s){s1 = apply(cbind(s, 0.5), MARGIN=1,FUN=max); return(1/s1)}

#Define max-combo test
maxcombo1 = list(lr)
maxcombo2 = list(lr, fh01)
maxcombo3 = list(lr, fh01, fh11)

maxcombo4 = list(lr, sfh01)
maxcombo5 = list(lr, mfh01)
maxcombo6 = list(lr, sfh01, mfh01, fh01)
F.entry = function(t){(t/18)^1.5*as.numeric(t <= 18) + as.numeric(t > 18)}
G.ltfu = function(t){0}

wlr.power.maxcombo(T = 36, events = NULL, alpha=c(0.05), 
  power = 0.9, side = 2, r = 1, n = NULL, 
  h0 = h0, S0=S0,h1 = h.D3, S1= S.D3, f.logHR = f.logHR.D3, 
  f.ws = list(FA=list(lr)), F.entry=F.entry, G.ltfu=G.ltfu)

#Equivalent to

wlr.power.maxcombo0(T = 36, events = NULL, alpha=c(0.05), 
  power = 0.9, side = 2, r = 1, n = NULL, 
  h0 = h0, S0=S0,h1 = h.D3, S1= S.D3, f.logHR = f.logHR.D3, 
  f.ws = list(FA=lr), F.entry=F.entry, G.ltfu=G.ltfu)
  
#Also equivalent to
wlr.power(T = 36, events = NULL, alpha=c(0.05), 
  power = 0.9, side = 2, r = 1, n = NULL, 
  h0 = h0, S0=S0,h1 = h.D3, S1= S.D3, f.logHR = f.logHR.D3, 
  f.ws = list(lr), F.entry=F.entry, G.ltfu=G.ltfu)

wlr.power.maxcombo(T = 36, events = NULL, alpha=c(0.025), 
  power = 0.9, side = 1, r = 1, n = NULL, 
  h0 = h0, S0=S0,h1 = h.D3, S1= S.D3, f.logHR = f.logHR.D3, 
  f.ws = list(FA=list(lr, fh01)), F.entry=F.entry, G.ltfu=G.ltfu)
  
wlr.power.maxcombo(T = NULL, events = 230, alpha=c(0.025), 
  power = 0.9, side = 1, r = 1, n = 400, 
  h0 = h0, S0=S0,h1 = h.D3, S1= S.D3, f.logHR = f.logHR.D3, 
  f.ws = list(FA=list(lr, fh01)), F.entry=F.entry, G.ltfu=G.ltfu)   
  
  #Equivalent to
wlr.power.maxcombo0(T = 36, events = NULL, alpha=c(0.025), 
  power = 0.9, side = 1, r = 1, n = NULL, 
  h0 = h0, S0=S0,h1 = h.D3, S1= S.D3, f.logHR = f.logHR.D3, 
  f.ws = list(lr, fh01), F.entry=F.entry, G.ltfu=G.ltfu)
  
wlr.power.maxcombo(T = 36, events = NULL, alpha=c(0.025), 
  power = 0.9, side = 1, r = 1, n = NULL, 
  h0 = h0, S0=S0,h1 = h.D3, S1= S.D3, f.logHR = f.logHR.D3, 
  f.ws = list(FA=list(lr, fh01, fh11)), F.entry=F.entry, G.ltfu=G.ltfu)

  #Equivalent to   
wlr.power.maxcombo0(T = 36, events = NULL, alpha=c(0.025), 
  power = 0.9, side = 1, r = 1, n = NULL, 
  h0 = h0, S0=S0,h1 = h.D3, S1= S.D3, f.logHR = f.logHR.D3, 
  f.ws = list(lr, fh01, fh11), F.entry=F.entry, G.ltfu=G.ltfu)
  
  #Group sequential design
  #IA1: logrank; IA2: max(logrank, fh01); FA: max(lr, fh01, fh11)
wlr.power.maxcombo(T = c(24, 36, 48), events = NULL, 
  alpha=c(0.01, 0.02, 0.02)/2, 
  power = 0.9, side = 1, r = 1, n = NULL, 
  h0 = h0, S0=S0,h1 = h.D3, S1= S.D3, f.logHR = f.logHR.D3, 
  f.ws = list(IA1 = list(lr), IA2 = list(lr, fh01), FA=list(lr, fh01, fh11)), 
  F.entry=F.entry, G.ltfu=G.ltfu)
  
  #log-rank test for IA1, IA2, and FA
wlr.power.maxcombo(T = c(24, 36, 48), events = NULL, 
  alpha=c(0.01, 0.02, 0.02)/2, 
  power = 0.9, side = 1, r = 1, n = NULL, 
  h0 = h0, S0=S0,h1 = h.D3, S1= S.D3, f.logHR = f.logHR.D3, 
  f.ws = list(IA1 = list(lr), IA2 = list(lr), FA=list(lr)), 
  F.entry=F.entry, G.ltfu=G.ltfu)
  
  #Equivalent to 
wlr.power(T = c(24, 36, 48), events = NULL, 
  alpha=c(0.01, 0.02, 0.02)/2, 
  power = 0.9, side = 1, r = 1, n = NULL, rho=NULL, gamma=NULL, s.tau=NULL,
  h0 = h0, S0=S0,h1 = h.D3, S1= S.D3, f.logHR = f.logHR.D3, 
  f.ws = list(lr, lr, lr), 
  F.entry=F.entry, G.ltfu=G.ltfu)
  
  #log-rank test for IA1, IA2, and FH01 for FA
wlr.power.maxcombo(T = c(24, 36, 48), events = NULL, 
  alpha=c(0.01, 0.02, 0.02)/2, 
  power = 0.9, side = 1, r = 1, n = NULL, 
  h0 = h0, S0=S0,h1 = h.D3, S1= S.D3, f.logHR = f.logHR.D3, 
  f.ws = list(IA1 = list(lr), IA2 = list(lr), FA=list(fh01)), 
  F.entry=F.entry, G.ltfu=G.ltfu)
  
wlr.power.maxcombo(T = NULL, events = c(40, 60, 80), 
  alpha=c(0.01, 0.02, 0.02)/2, 
  power = NULL, side = 1, r = 1, n = 100, 
  h0 = h0, S0=S0,h1 = h.D3, S1= S.D3, f.logHR = f.logHR.D3, 
  f.ws = list(IA1 = list(lr), IA2 = list(lr), FA=list(fh01)), 
  F.entry=F.entry, G.ltfu=G.ltfu)
  
  
}
